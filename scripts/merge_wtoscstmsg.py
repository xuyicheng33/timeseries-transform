"""
å…¨é‡åˆå¹¶ wtoscstmsg æ•°æ®é›†ï¼ˆé£æœº/å›è·¯æ•…éšœä¸æŒ¯è¡äº‹ä»¶æ—¥å¿—ï¼‰
- æŒ‰ STARTTIMEï¼ˆäº‹ä»¶å¼€å§‹æ—¶é—´ï¼‰æ’åº
- ä¸åšä»»ä½•æ•°æ®æ¸…æ´—
- ç”Ÿæˆä¸€ä¸ªå®Œæ•´æ–‡ä»¶
"""
import pandas as pd
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# é…ç½®
SOURCE_DIR = Path(r"E:\å¾…å¤„ç†æ•°æ®\wtoscstmsg")
OUTPUT_DIR = SOURCE_DIR / "wtoscstmsg_merged"
OUTPUT_FILE = OUTPUT_DIR / "wtoscstmsg_all.csv"

def detect_encoding(file_path, sample_size=10240):
    """æ£€æµ‹æ–‡ä»¶ç¼–ç """
    import chardet
    try:
        with open(file_path, 'rb') as f:
            raw = f.read(sample_size)
        result = chardet.detect(raw)
        return result.get('encoding', 'utf-8') or 'utf-8'
    except:
        return 'utf-8'


def merge_all():
    """å…¨é‡åˆå¹¶æ•°æ®"""
    print("="*80)
    print("å…¨é‡åˆå¹¶ wtoscstmsg æ•°æ®é›†ï¼ˆé£æœº/å›è·¯æ•…éšœä¸æŒ¯è¡äº‹ä»¶æ—¥å¿—ï¼‰")
    print("="*80)
    print(f"æºç›®å½•: {SOURCE_DIR}")
    print(f"è¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = sorted(SOURCE_DIR.glob("*.csv"))
    
    if not csv_files:
        print("âŒ æœªæ‰¾åˆ°CSVæ–‡ä»¶")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶")
    print()
    
    # è¯»å–å¹¶åˆå¹¶æ•°æ®
    print("å¼€å§‹è¯»å–å¹¶åˆå¹¶æ•°æ®...")
    all_data = []
    error_count = 0
    
    for i, file_path in enumerate(csv_files, 1):
        file_name = file_path.name
        
        try:
            # æ£€æµ‹ç¼–ç 
            encoding = detect_encoding(file_path)
            
            # è¯»å–æ–‡ä»¶
            df = pd.read_csv(file_path, encoding=encoding)
            
            if len(df) == 0:
                print(f"  [{i}/{len(csv_files)}] {file_name} - ç©ºæ–‡ä»¶ï¼Œè·³è¿‡")
                continue
            
            all_data.append(df)
            print(f"  [{i}/{len(csv_files)}] {file_name} - {len(df):,} è¡Œ")
        
        except Exception as e:
            print(f"  [{i}/{len(csv_files)}] {file_name} - âŒ é”™è¯¯: {e}")
            error_count += 1
    
    if not all_data:
        print("\nâŒ æ²¡æœ‰å¯åˆå¹¶çš„æ•°æ®")
        return
    
    print(f"\nâœ… è¯»å–å®Œæˆï¼ŒæˆåŠŸè¯»å– {len(all_data)} ä¸ªæ–‡ä»¶")
    if error_count > 0:
        print(f"âš ï¸  {error_count} ä¸ªæ–‡ä»¶è¯»å–å¤±è´¥")
    print()
    
    # åˆå¹¶æ‰€æœ‰æ•°æ®
    print("åˆå¹¶æ‰€æœ‰æ•°æ®...")
    merged_df = pd.concat(all_data, ignore_index=True)
    print(f"  åˆå¹¶å: {len(merged_df):,} è¡Œ")
    
    # æ˜¾ç¤ºåˆ—ä¿¡æ¯
    print(f"  åˆ—æ•°: {len(merged_df.columns)}")
    print(f"  åˆ—å: {merged_df.columns.tolist()}")
    
    # æŒ‰ STARTTIME æ’åº
    print("\næŒ‰ STARTTIMEï¼ˆäº‹ä»¶å¼€å§‹æ—¶é—´ï¼‰æ’åº...")
    try:
        merged_df['STARTTIME'] = pd.to_datetime(merged_df['STARTTIME'])
        merged_df = merged_df.sort_values('STARTTIME').reset_index(drop=True)
        print(f"  æ’åºå®Œæˆ: {len(merged_df):,} è¡Œ")
        print(f"  STARTTIME èŒƒå›´: {merged_df['STARTTIME'].min()} ~ {merged_df['STARTTIME'].max()}")
    except Exception as e:
        print(f"  âš ï¸  æ’åºæ—¶å‡ºç°é—®é¢˜: {e}")
        print(f"  å°†ä¿å­˜æœªæ’åºçš„æ•°æ®")
    
    # ä¿å­˜æ–‡ä»¶
    print("\nä¿å­˜æ–‡ä»¶...")
    # ç¡®ä¿æ—¶é—´æ ¼å¼å®Œæ•´ä¿å­˜ï¼ˆåŒ…å«æ—¶åˆ†ç§’ï¼‰
    if 'STARTTIME' in merged_df.columns:
        merged_df['STARTTIME'] = merged_df['STARTTIME'].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    merged_df.to_csv(OUTPUT_FILE, index=False, encoding='utf-8')
    
    file_size_mb = OUTPUT_FILE.stat().st_size / (1024 * 1024)
    print(f"  âœ… å·²ä¿å­˜: {OUTPUT_FILE.name}")
    print(f"  æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    
    # ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "="*80)
    print("åˆå¹¶å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯ï¼š")
    print("="*80)
    print(f"æ€»è®°å½•æ•°: {len(merged_df):,} è¡Œ")
    print(f"æ€»åˆ—æ•°: {len(merged_df.columns)} åˆ—")
    print(f"åˆ—å: {merged_df.columns.tolist()}")
    
    if 'STARTTIME' in merged_df.columns:
        try:
            print(f"\nSTARTTIME èŒƒå›´: {merged_df['STARTTIME'].min()} ~ {merged_df['STARTTIME'].max()}")
        except:
            pass
    
    # æ˜¾ç¤ºå„åˆ—çš„ç©ºå€¼ç»Ÿè®¡
    print("\nç©ºå€¼ç»Ÿè®¡:")
    null_found = False
    for col in merged_df.columns:
        null_count = merged_df[col].isna().sum()
        if null_count > 0:
            null_pct = (null_count / len(merged_df)) * 100
            print(f"  {col}: {null_count:,} ({null_pct:.2f}%)")
            null_found = True
    if not null_found:
        print("  æ— ç©ºå€¼ âœ…")
    
    # æ˜¾ç¤º WTID åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰
    if 'WTID' in merged_df.columns:
        print("\nWTID åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
        wtid_counts = merged_df['WTID'].value_counts().head(10)
        for wtid, count in wtid_counts.items():
            pct = (count / len(merged_df)) * 100
            print(f"  WTID {wtid}: {count:,} ({pct:.2f}%)")
        
        total_wtid = merged_df['WTID'].nunique()
        print(f"\n  æ€»å…± {total_wtid} ä¸ªä¸åŒçš„ WTID")
    
    # æ˜¾ç¤º FAULTNAME åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰
    if 'FAULTNAME' in merged_df.columns:
        print("\nFAULTNAME åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
        fault_counts = merged_df['FAULTNAME'].value_counts().head(10)
        for fault_name, count in fault_counts.items():
            pct = (count / len(merged_df)) * 100
            print(f"  {fault_name}: {count:,} ({pct:.2f}%)")
    
    # æ˜¾ç¤º OSCNAME åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰
    if 'OSCNAME' in merged_df.columns:
        print("\nOSCNAME åˆ†å¸ƒï¼ˆå‰10ä¸ªï¼‰:")
        osc_counts = merged_df['OSCNAME'].value_counts().head(10)
        for osc_name, count in osc_counts.items():
            pct = (count / len(merged_df)) * 100
            print(f"  {osc_name}: {count:,} ({pct:.2f}%)")
    
    print(f"\nè¾“å‡ºæ–‡ä»¶: {OUTPUT_FILE}")
    print("="*80)
    print("\nğŸ“‹ æ’åºè¯´æ˜ï¼š")
    print("  - æŒ‰ STARTTIMEï¼ˆäº‹ä»¶å¼€å§‹æ—¶é—´ï¼‰æ’åº")
    print("  - æ‰€æœ‰äº‹ä»¶æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ï¼Œä¾¿äºæ—¶åºåˆ†æ")
    print("="*80)


if __name__ == "__main__":
    try:
        merge_all()
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()

